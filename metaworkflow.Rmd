---
title: "Meta-Workflow"
author: "Miao Yu"
date: "August 16, 2016"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T)
```

## Introduction

The workflow of the metabolomic study always began with data collection and ended with certain scientific problem. It always showed the following workflow:

1. Experimental design(DoE)
2. Raw data collection
3. Feature detection
4. Data correction
5. Statistic analysis
6. Annotation
7. Omics analysis

## Project Setup

I suggest to build your data analysis project in RStudio(Click File - New project - New dictionary - Empty project). Then assign a name for your project. I recommend the following tips if you are familiar with it.

- Use [git](https://git-scm.com/)/[github](https://github.com/) to make version control of your code and sync your project online.

- NOT use your name for your project because other peoples might cooperate with you and someone might check your data when you publish your papers. Each project should be a work for one paper or one chapter in your thesis.

- Use **workflow** document(txt or doc) in your project to record all of the steps and code you performed for this project. Treat this document as digital version of your experiment notebook

- Use **data** folder in your project folder for the raw data and the results you get in data analysis

- Use **figure** folder in your project folder for the figure

- Use **munuscript** folder in your project folder for the manuscript (you could write paper in rstudio with the help of template in [Rmarkdown](https://github.com/rstudio/rticles))

- The best way to begin your study with project is copy the contents in this folder into your new project folder. Remember not copy the **metademo.Rproj** into your folder because you already have one.

- Just double click **[yourprojectname].Rproj** to start your project

## Exprimental design(DoE)

Before you perform any metabolomic studies, a clean and meaningful experimental design is always the best start. You need two groups at least: treated group and control group. 

If there are other co-factors, a Linear model or randomizing would be applied to eliminated their influences. You need to record the values of those co-factors for further data analysis. Common co-factors in metabolomic studies are age, gender, location, etc.

If you need data correction, some background or calibration samples are required. However, control samples could also be used for data correction in certain DoE.

## Raw data collection

Collection of your Raw data from the instrument such as LC-MS or GC-MS is the beginning of data analysis.

However, **xcms** does not support all of the Raw files from every mass spectrometry manufacturers. You need to convert your Raw data into some open-source [data format](https://en.wikipedia.org/wiki/Mass_spectrometry_data_format) such as mzData, mzXML or CDF files. The tool is **MScovert** from [**ProteoWizard**](http://proteowizard.sourceforge.net/).

Here is a demo:

```{r demo1,message=F,warning=FALSE}
# install the packages for data analysis and 
# source("https://bioconductor.org/biocLite.R")
# biocLite(c("multtest","faahKO","xcms","qvalue","CAMERA","ropls"))
# load the functions and dataset for demo

library(multtest)
library(xcms)
library(faahKO)
# get the demo data in faahKO packages
cdfpath <- system.file("cdf",package = "faahKO")
# show the name of demo data
list.files(cdfpath,recursive = T)
```


## Feature detection

The first step to process the MS data is that find the peaks against the noises. In **xcms**, all of related staffs are handled by *xcmsSet* function. 

For any functions in **xcms** or **R**, you could get their documents by type `?` before certain function. Another geek way is input the name of the function in the console of Rstudio and press F1 for help.

```{r demo2,eval=F}
?xcmsSet
```

In the document of *xcmsset*, we could set the sample classes, profmethod, profparam, polarity,etc. In the online version, such configurations are shown in certain windows. In the local analysis environment, such parameters are setup by yourselves. However, I think the default configurations could satisfied most of the analysis because related information should have been recorded in your Raw data and **xcms** could find them. All you need to do is that show the data dictionary for *xcmsSet*. 

If your data have many groups such as control and treated group, just put them in separate subfolder of the data folder and *xcmsSet* would read them as separated groups.

Here is a demo for *xcmsSet*:

```{r demo3,warning=F}
cdffiles <- list.files(cdfpath, recursive = TRUE, full.names = TRUE)
xset <- xcmsSet(cdffiles)
xset
```

The output was an object with class of *xcmsSet*. You could see a summary by type the name. In this cases, *xcmsSet* found 4721 peaks with time range 41.8-69.1 min and mass range 200.1-599.3338 m/z in the 12 samples.

Another function which might be useful is `group`. This function will add additional information about the same analytes for `xcmsSet` objects.

```{r demo4}
xset <- group(xset)
xset
```

Now you see there are 403 groups in the demo data, which meant 403 analytes are found across 4721 peaks.

## Data correction

Reasons of data correction might come from many aspects such as the unstable instrument and pollution on column. In **xcms**, the most important correction is retention time correction. 

The basic idea behind retention time correction is that use the high quality grouped peaks to make a new retention time. You might choose obiwarp(recommended, see this [paper](http://pubs.acs.org/doi/abs/10.1021/ac0605344)) or loess(defaulted) method to get the corrected retention time for all of the samples. Remember the original retention time might changed and use another object to save the new object:

```{r demo5}
xset2 <- retcor(xset, method = "obiwarp")
xset2
# you need group the peaks again for this corrected data
xset2 <- group(xset2)
xset2
```

You see one more peak groups after the correction. After the retention time correction, we also need to correct the peak groups by filling the missing peaks. Such function calls *fillpeaks*:

```{r demo6}
xset3 <- fillPeaks(xset2)
xset3
```

You see more peaks found.

## Statistic analysis

Right now we get peaks across samples, the next step is finding the differences between two groups. Actually, you could perform ANOVA or Kruskal-Wallis Test for comparison among more than two groups. The basic idea behind statistic analysis is to find the meaningful differences between groups and extract such ions or peak groups. So, you will find the P values of t-test for pairwise comparison:

```{r demo7}
reporttab <- diffreport(xset3, "WT", "KO", "example")
reporttab[1:3,]
```

Now you have got the ions that varies a lot between groups. Such ions are things we should take care of. In a ideal case, this is the endpoint of your study and the left work is making a report of your finding.

However, you might find too many ions and also hundreds of comparison would also show many high false-positive ions. In statistics, you need a false discovery rate(FDR) control. I suggested q-values instead of p-values to control FDR. If q-value is 0.05, we should expect 5% of all the compounds with q-value less than this to be false positives.

To get the q-values, you need input p-values and use the function from **qvalue** package.

```{r demo8}
library(qvalue)
# extract the p-value to caculate q-value
qvalue <- qvalue(p=reporttab$pvalue)
# add qvalue to reporttab
reporttab$qvalue <- qvalue$qvalues
reporttab[1:3,]
```

For further information about q-value, check [here](https://en.wikipedia.org/wiki/False_discovery_rate#q-value).

After the FDR control, the following steps depend on your study.

## Annotation

When you get the filtered ions, the next step is making annotation for them. I suggest **CAMERA** package to handle this task. You need to prepare an object of class *xcmsSet*, for example, *xset3*(remember to use *fillpeaks* to get the ions group).

```{r demo9}
library(CAMERA)
# Create an xsAnnotate object
xsa <- xsAnnotate(xset3)
# Group after RT value of the xcms grouped peak
xsaF <- groupFWHM(xsa, perfwhm=0.6)
# Verify grouping
xsaC <- groupCorr(xsaF)
# Annotate isotopes, could be done before groupCorr
xsaFI <- findIsotopes(xsaC)
# Annotate adducts
xsaFA <- findAdducts(xsaFI, polarity="positive")
# See the results
getPeaklist(xsaFA)[1:3,]
# Get final peaktable and store on harddrive
# write.csv(getPeaklist(xsaFA),file="data/result_CAMERA.csv")
```

Any steps after the *annotation* could be operated solo and you may not need the isotopes or adducts. You could also use *annotateDiffreport* to show the results as *diffreport* in **xcms**.

```{r demo10}
# make a diffreport with CAMERA result and extract the fold change higher than 3
dreport <- annotateDiffreport(xset3, fc_th = 3)
# extract the p-value to caculate q-value
qvalue <- qvalue(p=dreport$pvalue)
# add qvalue to reporttab
dreport$qvalue <- qvalue$qvalues
# See the results
dreport[1:3,]
# save on harddrive
# write.csv(dreport,file='data/diffreport.csv')
```

## Omics analysis

Since we have got the annotations, Omics analysis could be performed. In **xcms**, the default database is **metlin**. You could directly get the link to certain compounds when you generate the differences report.

```{r demo11}
# make a diffreport with CAMERA result and extract the fold change higher than 3, add the metlin links
dreport <- annotateDiffreport(xset3, fc_th = 3, metlin = T)
# extract the p-value to caculate q-value
qvalue <- qvalue(p=dreport$pvalue)
# add qvalue to reporttab
dreport$qvalue <- qvalue$qvalues
# See the results
dreport[1:3,]
# save on harddrive
# write.csv(dreport,file='data/diffreport.csv')
```

The other way to perform the Omics study is upload the data obtained from the **xcms** to other tools or databases.

You will get an updated database list [here](http://metabolomicssociety.org/resources/metabolomics-databases)

Right now, it is hard to connect different omics databases such as gene, protein and metabolites together for a whole scope of certain biological process. However, you might select few metabolites across those databases and find something interesting.

## Conclusion

This is the offline metaboliomics data process workflow. For each study, details would be different and F1 is always your best friend. 

Enjoy yourself in data mining!

## Algorithm code for data analysis

## K means

```{r demo12}
# get the ions for PCA
pdreport <- dreport[,15:26]
indx <- sapply(pdreport, is.factor)
pdreport[indx] <- lapply(pdreport[indx], function(x) as.numeric(as.character(x)))
tpdreport <- data.frame(t(pdreport))
labels <- c(1,1,1,1,1,1,2,2,2,2,2,2)
# get the cluster
library(cluster)
clus <- kmeans(tpdreport, centers=2)
dissE <- daisy(tpdreport) 
dE2   <- dissE^2
sk2   <- silhouette(clus$cl, dE2)
plot(sk2,main="1-6 for KO, 7-12 for WT")

```

## Hierarchical

```{r demo13}
# Ward Hierarchical Clustering
d <- dist(tpdreport, method = "euclidean") 
# distance matrix
fit <- hclust(d, method="ward") 
# display dendogram
plot(fit)
```


## PCA

```{r demo14}
# run PCA
pca <- prcomp(tpdreport, center=TRUE, scale=TRUE)
# loading plot
plot(pca, type = "l")
CP <- (pca$sdev^2/sum(pca$sdev^2))
x <- 1:12
plot(CP~x,
     cex = 2,
     pch = 19,
     type = "o",
     xlab = "Principal Components",
     ylab = "Proportion of Variance")
# biplot
biplot(pca)
plot(pca$x[,1], 
     pca$x[,2], 
     xlab="PC1",
     ylab="PC2",
     pch=rownames(tpdreport),
     cex=2)
```

## PLS-DA

```{r demo15}
library(ropls)
dplsda <- opls(tpdreport, as.factor(labels))
plot(dplsda)
```

## Tree

```{r demo16}
# install.packages('randomForest')
library(randomForest)
# grow tree
fit <- randomForest(y=as.factor(labels),x = as.matrix(tpdreport), importance=TRUE,ntree=200000)
varImpPlot(fit, n.var = 10)
```

## Useful links

- [Workshop slides](https://docs.google.com/presentation/d/1wuOiLa6XMZcoM_IRirQgT3z3fhnoGy4SRZYDNPI2J2o/edit?usp=sharing)

- [The Elements of Statistical Learning: Data Mining, Inference, and Prediction.](http://statweb.stanford.edu/~tibs/ElemStatLearn/)

- [Multivariate Analysis in Metabolomics](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4465187/)

- [Ropls packages](http://bioconductor.org/packages/release/bioc/html/ropls.html)

- [A tutorial review: Metabolomics and partial least squares-discriminant analysis – a marriage of convenience or a shotgun wedding](http://www.sciencedirect.com/science/article/pii/S0003267015001889)